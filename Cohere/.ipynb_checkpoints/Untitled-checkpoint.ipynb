{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f7778fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "co = cohere.Client('xK5Vyd8x0tTG8RdSBeIrsYPqwgfxI1AiW3EbUmdi', '2022-12-06')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70af7e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Passage: Is Wordle getting tougher to solve? Players seem to be convinced that the game has gotten harder in recent weeks ever since The New York Times bought it from developer Josh Wardle in late January. The Times has come forward and shared that this likely isn't the case. That said, the NYT did mess with the back end code a bit, removing some offensive and sexual language, as well as some obscure words There is a viral thread claiming that a confirmation bias was at play. One Twitter user went so far as to claim the game has gone to \"the dusty section of the dictionary\" to find its latest words.\n",
    "\n",
    "TLDR: Wordle has not gotten more difficult to solve.\n",
    "--\n",
    "Passage: ArtificialIvan, a seven-year-old, London-based payment and expense management software company, has raised $190 million in Series C funding led by ARG Global, with participation from D9 Capital Group and Boulder Capital. Earlier backers also joined the round, including Hilton Group, Roxanne Capital, Paved Roads Ventures, Brook Partners, and Plato Capital.\n",
    "\n",
    "TLDR: ArtificialIvan has raised $190 million in Series C funding.\n",
    "--\n",
    "Passage: The National Weather Service announced Tuesday that a freeze warning is in effect for the Bay Area, with freezing temperatures expected in these areas overnight. Temperatures could fall into the mid-20s to low 30s in some areas. In anticipation of the hard freeze, the weather service warns people to take action now.\n",
    "\n",
    "TLDR:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcc6a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = co.generate( \n",
    "    model='xlarge', \n",
    "    prompt = prompt,\n",
    "    max_tokens=40, \n",
    "    temperature=0.3,\n",
    "    stop_sequences=[\"--\"])\n",
    "\n",
    "summary = response.generations[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bf1b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aadf295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "585292ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  Atlanta, there was a salon that was filled with whimsical and enchanting stylists. The stylists would use their magic to make all of their clients look and feel like a princess. The salon was called Magic Mirror. The stylists had two\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = co.generate(\n",
    "  prompt='Once upon a time in a magical land called',\n",
    "  max_tokens=50)\n",
    "print('Prediction: {}'.format(response.generations[0].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "911b0d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = co.generate(\n",
    "        model='invalid-model',\n",
    "        prompt='sample prompt')\n",
    "except cohere.CohereError as e:\n",
    "    print(e.message)\n",
    "    print(e.http_status)\n",
    "    print(e.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eab7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate similarity between 2 texts using Embeddings\n",
    "### THIS COULD BE DONE TO CALC SIMILARITY BETWEEN WIKI DESCRIPTION AND USER DESCRIPTION\n",
    "\n",
    "import cohere\n",
    "import numpy as np\n",
    "\n",
    "co = cohere.Client(\"YOUR_API_KEY\")\n",
    "\n",
    "# get the embeddings\n",
    "phrases = [\"i love soup\", \"soup is my favorite\", \"london is far away\"]\n",
    "(soup1, soup2, london) = co.embed(phrases).embeddings\n",
    "\n",
    "# compare them\n",
    "def calculate_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "calculate_similarity(soup1, soup2) # 0.9 - very similar!\n",
    "calculate_similarity(soup1, london) # 0.3 - not similar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2d1a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prompt Engineering\n",
    "### Prompt Engineering could also be used to get a recommendation\n",
    "### THIS needs: prompt --> keywords (summary)\n",
    "###             wikip. --> keywords (summary)\n",
    "### THEN CALCULATE SIMILARITY BETWEEN KEYWORDS\n",
    "### Prompt formulation https://docs.cohere.ai/docs/prompt-engineering\n",
    "\n",
    "\"\"\"\n",
    "This is a bot that automatically finds the most important keyword for a given text passage. Text:\n",
    "\"BLABALBA.\"\n",
    "Most important key word: \"BLA\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd23c1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We can generate multiple suggestions using likelihoods\n",
    "### https://docs.cohere.ai/docs/number-of-generations\n",
    "### Then use top-k or top-p for further generation\n",
    "### https://docs.cohere.ai/docs/controlling-generation-with-top-k-top-p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d40d011",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Should create a custom model than compare it with baseline\n",
    "\n",
    "response = co.generate(\n",
    "  model='small', ### OR ID\n",
    "  prompt='To be, or not to be: that is the question: Whether â€™tis nobler in the mind to suffer The slings and arrows of outrageous fortune, Or to take arms against a sea of troubles, And by opposing end them. To die: to sleep...',\n",
    "  max_tokens=1,\n",
    "  temperature=1,\n",
    "  k=0,\n",
    "  p=0.75,\n",
    "  return_likelihoods='ALL')\n",
    "print('Likelihood: {}'.format(response.generations[0].likelihood))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "T",
   "language": "python",
   "name": "t"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
